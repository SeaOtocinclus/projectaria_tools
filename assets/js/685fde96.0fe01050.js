"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8684],{21673:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});var a=n(74848),s=n(28453);const o={sidebar_position:60,title:"HOT3D Dataset"},i="HOT3D Dataset",r={id:"open_datasets/hot3d",title:"HOT3D Dataset",description:"HOT3D is a new benchmark dataset for vision-based understanding of 3D hand-object interactions. This dataset contains over 800 minutes of egocentric recordings, with 33 diverse hand-held objects, capturing over one million multi-view frames of hand-object interactions.",source:"@site/docs/open_datasets/hot3d.mdx",sourceDirName:"open_datasets",slug:"/open_datasets/hot3d",permalink:"/projectaria_tools/docs/open_datasets/hot3d",draft:!1,unlisted:!1,editUrl:"https://github.com/facebookresearch/projectaria_tools/tree/main/website/docs/open_datasets/hot3d.mdx",tags:[],version:"current",sidebarPosition:60,frontMatter:{sidebar_position:60,title:"HOT3D Dataset"},sidebar:"tutorialSidebar",previous:{title:"DTC Tooling",permalink:"/projectaria_tools/docs/open_datasets/digital_twin_catalog/digital_twin_catalog_tooling"},next:{title:"Aria Everyday Objects Dataset",permalink:"/projectaria_tools/docs/open_datasets/aria_everyday_objects/"}},d={},c=[{value:"Getting Started",id:"getting-started",level:2},{value:"HOT3D Research Challenges",id:"hot3d-research-challenges",level:2}];function l(e){const t={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"hot3d-dataset",children:"HOT3D Dataset"})}),"\n",(0,a.jsx)(t.p,{children:"HOT3D is a new benchmark dataset for vision-based understanding of 3D hand-object interactions. This dataset contains over 800 minutes of egocentric recordings, with 33 diverse hand-held objects, capturing over one million multi-view frames of hand-object interactions."}),"\n",(0,a.jsx)(t.p,{children:"The dataset contains:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Synchronized multi-view egocentric videos from Project Aria glasses and Quest 3 VR headset"}),"\n",(0,a.jsx)(t.li,{children:"High-quality 3D pose annotations of hands and objects"}),"\n",(0,a.jsx)(t.li,{children:"3D object models with PBR materials"}),"\n",(0,a.jsx)(t.li,{children:"2D bounding boxes"}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"/projectaria_tools/docs/data_formats/mps/mps_eye_gaze",children:"Eye Gaze MPS data"})," (Aria only)"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"/projectaria_tools/docs/data_formats/mps/slam/mps_pointcloud",children:"Semi-Dense Point Cloud MPS data"})," (Aria only)"]}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"HOT3D uses its own specific downloader, available in the HOT3D GitHub repository, enabling you to download Quest3, Aria and object models data."}),"\n",(0,a.jsx)(t.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"https://www.projectaria.com/datasets/hot3D/",children:"https://www.projectaria.com/datasets/hot3D/"})," - find out more about the dataset and get access to it."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"https://arxiv.org/pdf/2406.09598",children:"Introducing HOT3D: An Egocentric Dataset for 3D Hand and Object Tracking"})," - research paper."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"https://github.com/facebookresearch/hot3d",children:"HOT3D GitHub repository"})," - install HOT3D Python tooling that will enable you to download and visualize HOT3D data.","\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["Use the ",(0,a.jsx)(t.a,{href:"https://github.com/facebookresearch/hot3d/blob/main/hot3d/HOT3D_Tutorial.ipynb",children:"HOT3D Jupyter notebook tutorial"})," to get to know the downloader and visualizers."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.h2,{id:"hot3d-research-challenges",children:"HOT3D Research Challenges"}),"\n",(0,a.jsx)(t.p,{children:"HOT3D data is used in the following research challenges:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.a,{href:"https://github.com/facebookresearch/hand_tracking_toolkit?tab=readme-ov-file#evaluation",children:"Multiview Egocentric Hand Tracking Challenge"})}),"\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.a,{href:"https://bop.felk.cvut.cz/challenges/bop-challenge-2024/",children:"BOP: Benchmark for 6D Object Pose Estimation"})}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>r});var a=n(96540);const s={},o=a.createContext(s);function i(e){const t=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),a.createElement(o.Provider,{value:t},e.children)}}}]);