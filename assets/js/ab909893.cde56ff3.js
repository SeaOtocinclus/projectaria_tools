"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[842],{62411:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>i,metadata:()=>a,toc:()=>l});var n=r(74848),o=r(28453);const i={sidebar_position:20,title:"Egocentric Voxel Lifting (EVL)"},s="Egocentric Voxel Lifting (EVL)",a={id:"open_models/evl",title:"Egocentric Voxel Lifting (EVL)",description:"Overview",source:"@site/docs/open_models/evl.mdx",sourceDirName:"open_models",slug:"/open_models/evl",permalink:"/projectaria_tools/docs/open_models/evl",draft:!1,unlisted:!1,editUrl:"https://github.com/facebookresearch/projectaria_tools/tree/main/website/docs/open_models/evl.mdx",tags:[],version:"current",sidebarPosition:20,frontMatter:{sidebar_position:20,title:"Egocentric Voxel Lifting (EVL)"},sidebar:"tutorialSidebar",previous:{title:"EgoBlur",permalink:"/projectaria_tools/docs/open_models/egoblur"},next:{title:"Eye Tracking",permalink:"/projectaria_tools/docs/open_models/eye_tracking"}},c={},l=[{value:"Overview",id:"overview",level:2},{value:"Further reading",id:"further-reading",level:3},{value:"Getting Started",id:"getting-started",level:2}];function d(e){const t={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",ul:"ul",...(0,o.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"egocentric-voxel-lifting-evl",children:"Egocentric Voxel Lifting (EVL)"})}),"\n",(0,n.jsx)(t.h2,{id:"overview",children:"Overview"}),"\n",(0,n.jsxs)(t.p,{children:["EVL is an opensource AI model from Meta for 3D object detection and surface reconstruction on ProjectAria recordings.\nEVL is trained on simulation data, namely ",(0,n.jsx)(t.a,{href:"https://www.projectaria.com/datasets/ase/",children:"Aria Synthetic Environments"}),".\nIt relies on frozen 2D foundation features to set a competitive performance. EVL leverages all egocentric modalities from Aria\nincluding posed and calibrated RGB and greyscale video streams and semidense points."]}),"\n",(0,n.jsx)(t.h3,{id:"further-reading",children:"Further reading"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["Research Paper - ",(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2406.10224",children:"EFM3D: A Benchmark for Measuring Progress Towards 3D Egocentric Foundation Models"})]}),"\n",(0,n.jsxs)(t.li,{children:["Github repo ",(0,n.jsx)(t.a,{href:"https://github.com/facebookresearch/efm3d",children:"github.com/facebookresearch/efm3d"})]}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,n.jsxs)(t.p,{children:["To start using the model, check out the EVL model inference ",(0,n.jsx)(t.a,{href:"https://github.com/facebookresearch/efm3d",children:"demo"})," in the EFM3D repo."]})]})}function h(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},28453:(e,t,r)=>{r.d(t,{R:()=>s,x:()=>a});var n=r(96540);const o={},i=n.createContext(o);function s(e){const t=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),n.createElement(i.Provider,{value:t},e.children)}}}]);